{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e1f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb781e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.cpu_num_threads = 14\n",
    "        self.workdir = \"D:/bioinformatics/python/bioinformation/机器学习/EsophagealCancerResnet/\"\n",
    "        self.data_folder = self.workdir + \"data/\" + \"available_data/\"\n",
    "        self.result_folder = \"./reslut/\"\n",
    "        self.folder_classes = [\"train\", \"test\", \"ind\"]\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#         self.device = 'cpu'\n",
    "        self.batch_size = 8\n",
    "        self.early_stop = 100\n",
    "        self.epoches = 100\n",
    "        \n",
    "        os.chdir(self.workdir)\n",
    "        torch.set_num_threads(self.cpu_num_threads)\n",
    "        if not os.path.exists(self.result_folder):\n",
    "            os.makedirs(self.result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab0c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d516cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(imgs_path):\n",
    "    \"\"\"由图片名称判读图片类别，并以列表形式返回\"\"\"\n",
    "    label = []\n",
    "    for img_path in imgs_path:\n",
    "        label.append(int(img_path[-5]))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775025a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16009, 4003, 4003, 16009, 4003, 4003)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "train_imgs_path = glob.glob(config.data_folder + \"train/*.jpg\")\n",
    "test_imgs_path = glob.glob(config.data_folder + \"test/*.jpg\")\n",
    "ind_imgs_path = glob.glob(config.data_folder + \"ind/*.jpg\")\n",
    "train_label, test_label, ind_label = get_label(train_imgs_path), get_label(test_imgs_path), get_label(ind_imgs_path)\n",
    "len(train_imgs_path), len(test_imgs_path), len(ind_imgs_path), len(train_label), len(test_label), len(ind_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4880bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs_path, labels_num):\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.Resize((837, 837)),\n",
    "                            torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "        self.imgs_path = imgs_path\n",
    "        self.labels = labels_num\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.imgs_path[index], self.labels[index]\n",
    "        img_pil = Image.open(img_path)\n",
    "        img_np = np.array(img_pil)\n",
    "        if len(img_np.shape) == 2:\n",
    "            img_np = np.repeat(img_np[:, :, np.newaxis], 3, axis=2)\n",
    "            img_pil = Image.fromarray(img_np)\n",
    "        img = self.transform(img_pil)\n",
    "        label = torch.tensor(label, dtype=torch.int64)\n",
    "        return img.type(torch.float32), label\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a0fdf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fc(torch.nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(Fc, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_features=in_features, out_features=256)\n",
    "        self.linear2 = torch.nn.Linear(in_features=256, out_features=64)\n",
    "        self.linear3 = torch.nn.Linear(in_features=64, out_features=5)\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), -1)\n",
    "        x = F.dropout(F.relu(self.linear1(input)), p=0.5)\n",
    "        x = F.dropout(F.relu(self.linear2(x)), p=0.5)\n",
    "        logits = self.linear3(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33be5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        resnet_model = torchvision.models.resnet152(pretrained=True)\n",
    "        in_features = resnet_model.fc.in_features\n",
    "        resnet_model = torch.nn.Sequential(*(list(resnet_model.children())[:-1]))\n",
    "        self.resnet_model = resnet_model\n",
    "        self.fc = Fc(in_features)\n",
    "    def forward(self, input):\n",
    "        x = self.resnet_model(input)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2404e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dl, model, loss_fn, optim, device, is_acc=False):\n",
    "    model.train()\n",
    "    train_data_num = len(train_dl.dataset)\n",
    "    acc_epoch, loss_epoch = 0, 0\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            acc_epoch += (pred.argmax(1) == y).sum().item()\n",
    "            loss_epoch += loss.item()\n",
    "    loss_epoch = loss_epoch/train_data_num\n",
    "    if is_acc:\n",
    "        acc_epoch = acc_epoch/train_data_num\n",
    "        return loss_epoch, acc_epoch\n",
    "    else:\n",
    "        return loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f08e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_dl, model, loss_fn, device, is_acc=False):\n",
    "    model.eval()\n",
    "    test_data_num = len(test_dl.dataset)\n",
    "    acc_epoch, loss_epoch = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            acc_epoch += (pred.argmax(1) == y).sum().item()\n",
    "            loss_epoch += loss.item()\n",
    "        loss_epoch = loss_epoch/test_data_num\n",
    "        if is_acc:\n",
    "            acc_epoch = acc_epoch/test_data_num\n",
    "            return loss_epoch, acc_epoch\n",
    "        else:\n",
    "            return loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "257e50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoches, train_dl, test_dl, ind_dl, model, optim, loss_fn, exp_lr_scheduler,\\\n",
    "        device, batch_size, config, test_best_loss=float(\"inf\")):\n",
    "    loss_epoches, best_model, is_improve, not_improve_num = [], model, \"\", 0\n",
    "    for epoch in range(epoches):\n",
    "        train_loss_epoch = train(train_dl, model, loss_fn, optim, device)\n",
    "        test_loss_epoch = test(test_dl, model, loss_fn, device)\n",
    "        if test_loss_epoch < test_best_loss:\n",
    "            best_model = model\n",
    "            test_best_loss = test_loss_epoch\n",
    "            not_improve_num = 0\n",
    "            is_improve = \"+\"\n",
    "        else:\n",
    "            not_improve_num += 1\n",
    "            is_improve = \"\"\n",
    "        if not_improve_num > config.early_stop:\n",
    "            break\n",
    "        loss_epoches.append([train_loss_epoch, test_loss_epoch])\n",
    "        exp_lr_scheduler.step()\n",
    "        template = \"epoch:{:<2}, train_loss:{:.5f}, test_loss:{:.5f} {}\"\n",
    "        print(template.format(epoch, train_loss_epoch, test_loss_epoch, is_improve))\n",
    "    test_best_loss, test_best_acc = test(test_dl, best_model, loss_fn, device, is_acc=True)\n",
    "    ind_best_loss, ind_best_acc = test(ind_dl, best_model, loss_fn, device, is_acc=True)\n",
    "    torch.save(best_model.state_dict(), config.result_folder + 'Resnet.pth')\n",
    "    template = \"test_best_loss:{}, ind_best_loss:{}, test_best_acc:{}, ind_best_acc:{}\"\n",
    "    print(template.format(test_best_loss, ind_best_loss, test_best_acc, ind_best_acc))\n",
    "    return np.array(loss_epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d742df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_x, train_y, test_x, test_y, ind_x, ind_y, config):\n",
    "    train_ds = MyDataset(train_x, train_y)\n",
    "    test_ds = MyDataset(test_x, test_y)\n",
    "    ind_ds = MyDataset(ind_x, ind_y)\n",
    "    train_dl = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=config.batch_size, shuffle=False)\n",
    "    ind_dl = DataLoader(ind_ds, batch_size=config.batch_size, shuffle=False)\n",
    "    model = Model().to(config.device)\n",
    "#     for p in model.resnet_model.parameters():\n",
    "#             p.requires_grad = False\n",
    "#     optim = torch.optim.Adam(model.fc.parameters(), lr=0.01)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    exp_lr_scheduler_1 = torch.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.5)\n",
    "    loss_epoches_fc  = fit(config.epoches, train_dl, test_dl, ind_dl, model, optim, loss_fn, \\\n",
    "                           exp_lr_scheduler_1, config.device, config.batch_size, config)\n",
    "    return loss_epoches_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf610831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , train_loss:0.06098, test_loss:0.08740 +\n",
      "epoch:1 , train_loss:0.05019, test_loss:0.04612 +\n",
      "epoch:2 , train_loss:0.04713, test_loss:0.04869 \n",
      "epoch:3 , train_loss:0.04465, test_loss:0.04232 +\n",
      "epoch:4 , train_loss:0.04389, test_loss:0.04270 \n",
      "epoch:5 , train_loss:0.04196, test_loss:0.05564 \n",
      "epoch:6 , train_loss:0.04116, test_loss:0.04073 +\n",
      "epoch:7 , train_loss:0.04112, test_loss:0.03861 +\n",
      "epoch:8 , train_loss:0.03972, test_loss:0.03931 \n",
      "epoch:9 , train_loss:0.03928, test_loss:0.03762 +\n",
      "epoch:10, train_loss:0.03683, test_loss:0.03659 +\n",
      "epoch:11, train_loss:0.03656, test_loss:0.03735 \n",
      "epoch:12, train_loss:0.03621, test_loss:0.03665 \n",
      "epoch:13, train_loss:0.03560, test_loss:0.03716 \n",
      "epoch:14, train_loss:0.03499, test_loss:0.03569 +\n",
      "epoch:15, train_loss:0.03534, test_loss:0.03804 \n",
      "epoch:16, train_loss:0.03509, test_loss:0.03491 +\n",
      "epoch:17, train_loss:0.03358, test_loss:0.03516 \n",
      "epoch:18, train_loss:0.03358, test_loss:0.03603 \n",
      "epoch:19, train_loss:0.03383, test_loss:0.03517 \n",
      "epoch:20, train_loss:0.03257, test_loss:0.03485 +\n",
      "epoch:21, train_loss:0.03219, test_loss:0.03586 \n",
      "epoch:22, train_loss:0.03251, test_loss:0.03294 +\n",
      "epoch:23, train_loss:0.03175, test_loss:0.03472 \n",
      "epoch:24, train_loss:0.03135, test_loss:0.03393 \n",
      "epoch:25, train_loss:0.03195, test_loss:0.03340 \n",
      "epoch:26, train_loss:0.03158, test_loss:0.03355 \n",
      "epoch:27, train_loss:0.03125, test_loss:0.03391 \n",
      "epoch:28, train_loss:0.03141, test_loss:0.03394 \n",
      "epoch:29, train_loss:0.03127, test_loss:0.03284 +\n",
      "epoch:30, train_loss:0.02978, test_loss:0.03447 \n",
      "epoch:31, train_loss:0.03020, test_loss:0.03238 +\n",
      "epoch:32, train_loss:0.02941, test_loss:0.03264 \n",
      "epoch:33, train_loss:0.02961, test_loss:0.03325 \n",
      "epoch:34, train_loss:0.02949, test_loss:0.03479 \n",
      "epoch:35, train_loss:0.02947, test_loss:0.03353 \n",
      "epoch:36, train_loss:0.02892, test_loss:0.03547 \n",
      "epoch:37, train_loss:0.02829, test_loss:0.03403 \n",
      "epoch:38, train_loss:0.02882, test_loss:0.03566 \n",
      "epoch:39, train_loss:0.02873, test_loss:0.03486 \n",
      "epoch:40, train_loss:0.02808, test_loss:0.03519 \n",
      "epoch:41, train_loss:0.02773, test_loss:0.03307 \n",
      "epoch:42, train_loss:0.02748, test_loss:0.03406 \n",
      "epoch:43, train_loss:0.02711, test_loss:0.03595 \n",
      "epoch:44, train_loss:0.02718, test_loss:0.03414 \n",
      "epoch:45, train_loss:0.02682, test_loss:0.03499 \n",
      "epoch:46, train_loss:0.02658, test_loss:0.03512 \n",
      "epoch:47, train_loss:0.02689, test_loss:0.03446 \n",
      "epoch:48, train_loss:0.02663, test_loss:0.03532 \n",
      "epoch:49, train_loss:0.02661, test_loss:0.03601 \n",
      "epoch:50, train_loss:0.02599, test_loss:0.03672 \n",
      "epoch:51, train_loss:0.02563, test_loss:0.03650 \n",
      "epoch:52, train_loss:0.02551, test_loss:0.03585 \n",
      "epoch:53, train_loss:0.02539, test_loss:0.03555 \n",
      "epoch:54, train_loss:0.02620, test_loss:0.03601 \n",
      "epoch:55, train_loss:0.02591, test_loss:0.03681 \n",
      "epoch:56, train_loss:0.02536, test_loss:0.03585 \n",
      "epoch:57, train_loss:0.02495, test_loss:0.03890 \n",
      "epoch:58, train_loss:0.02512, test_loss:0.03611 \n",
      "epoch:59, train_loss:0.02477, test_loss:0.03697 \n",
      "epoch:60, train_loss:0.02457, test_loss:0.03724 \n",
      "epoch:61, train_loss:0.02642, test_loss:0.03742 \n",
      "epoch:62, train_loss:0.02413, test_loss:0.03958 \n"
     ]
    }
   ],
   "source": [
    "loss_epoches = main(train_imgs_path, train_label, test_imgs_path, test_label, ind_imgs_path, ind_label, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599953dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(loss_epoches, config):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Train loss\")\n",
    "    plt.plot(loss_epoches[:, 0])\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Test loss\")\n",
    "    plt.plot(loss_epoches[:, 1])\n",
    "    plt.savefig(config.result_folder + 'loss.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(loss_epoches, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33803d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
